{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"6-sent2vec-BERT","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMLuiD5uN16NcFtCq4Xgj6w"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"cjML9dWlYuv5"},"source":["# Text similarity by sent2vec\n","\n","Encoding is the task of representing text data (words, sentences or documents) into high-dimensional vectors. \n","\n","Sentence embedding (representation of sentences by vectors) helps us to tackle NLP tasks such as text classification or text summarization. \n","\n","In the past, we mostly used encondes such as  one-hot, term-frequency, or TF-IDF. The main drawback of these methods is that they are not able to capture syntactic and semantic information. \n","\n","The recent advancements in deep larning (such as neural word embedding models or BERT) are able to encode sentences or words in more meaningful forms. \n","\n","In this notebook, we learn how to work with the open-source **sent2vec** Python library to encode sentences. We will see two different methods to calculate the text similarity between two texts:\n","- By using BERT\n","- Using word2vec\n","\n","\n","Source: https://towardsdatascience.com/how-to-compute-sentence-similarity-using-bert-and-word2vec-ab0663a5d64\n"]},{"cell_type":"markdown","metadata":{"id":"ZcL57X9XaBEN"},"source":["First of all, we need to install this library.\n","\n","Note: sent2vec has dependencies with other libraries such as Spacy (for text cleaning), Gensim (for word2vec models), and Transformers (for various forms of BERT model). Maybe, you also need to install them. "]},{"cell_type":"code","metadata":{"id":"1fa1okj5Ytb2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626084579595,"user_tz":-120,"elapsed":3243,"user":{"displayName":"ISABEL SEGURA BEDMAR","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiQ1FNrqSnUE2MEN5-mH-AjUf5Ch9orkmSxxfel=s64","userId":"10362143810849156637"}},"outputId":"74b0222e-d1cf-4ff1-88a5-9359f86e0b38"},"source":["!pip3 install sent2vec\n"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: sent2vec in /usr/local/lib/python3.7/dist-packages (0.2.0)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (from sent2vec) (4.8.2)\n","Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from sent2vec) (1.9.0+cu102)\n","Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (from sent2vec) (2.2.4)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from sent2vec) (1.19.5)\n","Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (from sent2vec) (3.6.0)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers->sent2vec) (4.6.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers->sent2vec) (20.9)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers->sent2vec) (0.0.45)\n","Requirement already satisfied: huggingface-hub==0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers->sent2vec) (0.0.12)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers->sent2vec) (3.0.12)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers->sent2vec) (2019.12.20)\n","Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers->sent2vec) (0.10.3)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from transformers->sent2vec) (3.13)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers->sent2vec) (4.41.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers->sent2vec) (2.23.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->sent2vec) (3.7.4.3)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy->sent2vec) (3.0.5)\n","Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy->sent2vec) (1.1.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy->sent2vec) (57.0.0)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy->sent2vec) (1.0.5)\n","Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy->sent2vec) (0.8.2)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy->sent2vec) (2.0.5)\n","Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy->sent2vec) (1.0.0)\n","Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy->sent2vec) (7.4.0)\n","Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy->sent2vec) (1.0.5)\n","Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy->sent2vec) (0.4.1)\n","Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim->sent2vec) (1.15.0)\n","Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim->sent2vec) (5.1.0)\n","Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim->sent2vec) (1.4.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers->sent2vec) (3.4.1)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers->sent2vec) (2.4.7)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers->sent2vec) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers->sent2vec) (1.0.1)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers->sent2vec) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers->sent2vec) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers->sent2vec) (2021.5.30)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers->sent2vec) (3.0.4)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Xmhn9tfRafSC"},"source":["##Â 2) Using BERT to compute similarity\n","\n","In the following example, we use the BERT language model (which is supported by sent2vec) to encode several sentences and then measure their similarities. \n","\n","Currently, the sent2vec library only supports the DistilBERT model (which is Smaller, faster, cheaper, lighter version of BERT). \n","\n"]},{"cell_type":"code","metadata":{"id":"u_wy40paawFU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626084621646,"user_tz":-120,"elapsed":2848,"user":{"displayName":"ISABEL SEGURA BEDMAR","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiQ1FNrqSnUE2MEN5-mH-AjUf5Ch9orkmSxxfel=s64","userId":"10362143810849156637"}},"outputId":"59de3df9-1fdf-4fbc-971d-c9c788b032a6"},"source":["from sent2vec.vectorizer import Vectorizer\n","sentences = [\n","    \"Boris Johnson congratulates Joe Biden on US election win.\",\n","    \"Boris Johnson congratulates Joe Biden on 2020 election.\",\n","    \"Putin does not congratulate Joe Biden on US election win.\"\n","   # \"George W. Bush congratulates Joe Biden on 2020 election.\",\n","]\n","\n","#we create an Vectorizer object to represent the sentences\n","vectorizer = Vectorizer()\n","#we use the BERT language model\n","vectorizer.bert(sentences)\n","#we get their vectors\n","vectors_bert = vectorizer.vectors\n"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"AsV211DRbyWB"},"source":["Then, we can measure their similarities. To do this, we use the scipy library for numerical integration, interpolation, optimization, linear algebra, and statistics. In particular, the spatial package contienes routines to measure distances between vectors."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RjwffsYl85MG","executionInfo":{"status":"ok","timestamp":1626084625079,"user_tz":-120,"elapsed":224,"user":{"displayName":"ISABEL SEGURA BEDMAR","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiQ1FNrqSnUE2MEN5-mH-AjUf5Ch9orkmSxxfel=s64","userId":"10362143810849156637"}},"outputId":"247454e8-a9b7-48c8-c11f-ace4afaf9040"},"source":["\n","from sklearn.metrics.pairwise import cosine_similarity\n","cosine_similarity(\n","    [vectors_bert[0]],\n","    vectors_bert[1:]\n",")\n"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.9827911, 0.9387848]], dtype=float32)"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"T-bKp8rObywB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626084632396,"user_tz":-120,"elapsed":226,"user":{"displayName":"ISABEL SEGURA BEDMAR","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiQ1FNrqSnUE2MEN5-mH-AjUf5Ch9orkmSxxfel=s64","userId":"10362143810849156637"}},"outputId":"2370ea63-8470-41c6-93eb-588c9a418d27"},"source":["from scipy import spatial\n","\n","dist_1 = spatial.distance.cosine(vectors_bert[0], vectors_bert[1])\n","dist_2 = spatial.distance.cosine(vectors_bert[0], vectors_bert[2])\n","print('dist_1: {0}, dist_2: {1}'.format(dist_1, dist_2))\n","# dist_1: 0.043, dist_2: 0.192"],"execution_count":14,"outputs":[{"output_type":"stream","text":["dist_1: 0.017208755016326904, dist_2: 0.06121516227722168\n"],"name":"stdout"}]}]}