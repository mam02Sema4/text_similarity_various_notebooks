{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MetricsJaccardRouge.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPDGGuHOfbvCzxwNi9luUvQ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"rnyrJpxle6po"},"source":["# Metrics for text similarity: Jaccard and Rouge\n","\n","\n","There are several metrics that we can use to measure the similarity of two texts. In this notebook, we will review and implement some of these metrics.  \n","Source: \n","https://towardsdatascience.com/overview-of-text-similarity-metrics-3397c4601f50\n","\n","\n","The most popular metrics to measure the text similarity are: **Jaccard similarity** and **cosine distance**. \n","\n","**Jaccard similarity** one only focuses on lexical similarity, that is, it is based on the number of words that two texts share in common. However, this approach is not able to capture the semantic similarity of words (for example, synonyms, anotonyms). \n","\n","On the other hand, the similarity provided by the **cosine distance** depends on the quality of embeddings (vectors). If the vectors capture semantic and syntactic relations between words in a text, the cosine distance should be able to reflect these relations, becoming a better metric for text similarity. \n","\n","##Â Jacard similarity\n","Let me explain, start with the definition of \"Jacard similarity\". It is defined with the following equation:\n","\n","<img src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/9dfe117504d4a74fc8f5d44445756380153cd576\">\n","\n","where A and B are sentences (texts). \n","\n","\n","Below we implement the funcion and apply it to several pair of sentences to compare them."]},{"cell_type":"code","metadata":{"id":"dqSjYMT-e5oa","executionInfo":{"status":"ok","timestamp":1625822650651,"user_tz":-120,"elapsed":195,"user":{"displayName":"ISABEL SEGURA BEDMAR","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiQ1FNrqSnUE2MEN5-mH-AjUf5Ch9orkmSxxfel=s64","userId":"10362143810849156637"}}},"source":["def get_jaccard_sim(text1, text2):\n","    \"\"\"calculates the jaccard similarity of the two input texts\"\"\" \n","    tokens1 = set(text1.split())  #gets the unique tokens in text1\n","    tokens2 = set(text2.split())   #gets the unique tokens in text1\n","    common = tokens1.intersection(tokens2) #gets the list of tokens in common\n","    union = tokens1.union(tokens2) #gets the list of tokens in common\n","    \n","    #jaccard is the the number of words in common between the number of words in both sentences\n","    return len(common) / len(union)\n","\n"],"execution_count":44,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0ek6rbxGhEpB","executionInfo":{"status":"ok","timestamp":1625822653551,"user_tz":-120,"elapsed":3,"user":{"displayName":"ISABEL SEGURA BEDMAR","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiQ1FNrqSnUE2MEN5-mH-AjUf5Ch9orkmSxxfel=s64","userId":"10362143810849156637"}},"outputId":"7343ef4b-b46f-44c1-95a9-4aded254f6cf"},"source":["s1=\"Where can I find the user guide?\"\n","print(\"\\njaccard similarity of '{}' and '{}' is : {}\".format(s1,s1,get_jaccard_sim(s1,s1)))\n","\n","s2=\"Where can I find the true love?\"\n","print(\"\\njaccard similarity of '{}' and '{}' is : {}\".format(s1,s2,get_jaccard_sim(s1,s2)))\n","\n","s2=\"Where are the manual?\"\n","print(\"\\njaccard similarity of '{}' and '{}' is : {}\".format(s1,s2,get_jaccard_sim(s1,s2)))"],"execution_count":45,"outputs":[{"output_type":"stream","text":["\n","jaccard similarity of 'Where can I find the user guide?' and 'Where can I find the user guide?' is : 1.0\n","\n","jaccard similarity of 'Where can I find the user guide?' and 'Where can I find the true love?' is : 0.5555555555555556\n","\n","jaccard similarity of 'Where can I find the user guide?' and 'Where are the manual?' is : 0.2222222222222222\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"48cij7ZCih0c"},"source":["We can improve the implementation of this function. For example, it should not have to be case sensitive. The two following sentences: \n","- s1=\"Where can I find the user guide?\"\n","- s2=\"where can i find the user guide?\"\n","\n","are the same except some words in lowercase. The jaccard score for them is only 0.55!!!\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x02GKBlaihFV","executionInfo":{"status":"ok","timestamp":1625823398574,"user_tz":-120,"elapsed":203,"user":{"displayName":"ISABEL SEGURA BEDMAR","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiQ1FNrqSnUE2MEN5-mH-AjUf5Ch9orkmSxxfel=s64","userId":"10362143810849156637"}},"outputId":"528c1211-a740-42bf-a388-46fd4decb590"},"source":["s1=\"Where can I find the user guide?\"\n","s2=\"where can i find the user guide?\"\n","print(\"\\njaccard similarity of '{}' and '{}' is : {}\".format(s1,s2,get_jaccard_sim(s1,s2)))\n","\n"],"execution_count":75,"outputs":[{"output_type":"stream","text":["\n","jaccard similarity of 'Where can I find the user guide?' and 'where can i find the user guide?' is : 0.5555555555555556\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"D8IAd1vCgYU7"},"source":["Now we redefine the function to transform the tokens to lowercase. \n","Moreover, we will use the library Spacy to process the sentences. \n"]},{"cell_type":"code","metadata":{"id":"YTkZEsxIf-yP"},"source":["#!python3 -m spacy download en_core_web_sm\n","\n","import spacy\n","nlp = spacy.load('en_core_web_sm')           # load model package \"en_core_web_sm\"\n","print('spacy.en loaded')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"v5ijRQkJgXfI","executionInfo":{"status":"ok","timestamp":1625823470951,"user_tz":-120,"elapsed":211,"user":{"displayName":"ISABEL SEGURA BEDMAR","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiQ1FNrqSnUE2MEN5-mH-AjUf5Ch9orkmSxxfel=s64","userId":"10362143810849156637"}}},"source":["def get_jaccard_sim2(text1, text2):\n","    \"\"\"calculates the jaccard similarity of the two input texts. \n","    tokens are transformed to lowercase\"\"\" \n","    doc1=nlp(text1)\n","    doc2=nlp(text2)\n","    tokens1=[token.text.lower() for token in doc1]\n","    tokens2=[token.text.lower() for token in doc2]\n","    \n","    set1 = set(tokens1)\n","    set2 = set(tokens2)\n","\n","    set_union = set1.union(set2)\n","    set_intersection = set1.intersection(set2)\n","    \n","    result=len(set_intersection) / len(set_union)\n","    \n","    return result"],"execution_count":76,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6vjlKeP5hnG3","executionInfo":{"status":"ok","timestamp":1625823167123,"user_tz":-120,"elapsed":205,"user":{"displayName":"ISABEL SEGURA BEDMAR","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiQ1FNrqSnUE2MEN5-mH-AjUf5Ch9orkmSxxfel=s64","userId":"10362143810849156637"}},"outputId":"1ee55809-22b4-42f8-f53f-766ef8b2d688"},"source":["s1=\"Where can I find the user guide?\"\n","s2=\"where can i find the user guide?\"\n","print(\"\\njaccard similarity (version 1) of '{}' and '{}' is : {}\".format(s1,s2,get_jaccard_sim(s1,s2)))\n","print(\"jaccard similarity (version 2) of '{}' and '{}' is : {}\".format(s1,s2,get_jaccard_sim2(s1,s2)))\n"],"execution_count":70,"outputs":[{"output_type":"stream","text":["\n","jaccard similarity (version 1) of 'Where can I find the user guide?' and 'where can i find the user guide?' is : 0.5555555555555556\n","jaccard similarity (version 2) of 'Where can I find the user guide?' and 'where can i find the user guide?' is : 1.0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"25TmupyDfexC"},"source":["Moreover, we can also use lemmas (or stems) instead of tokens, to reduce the vocabulary. "]},{"cell_type":"markdown","metadata":{"id":"3RFXgRl0l3Vu"},"source":["Another improvement is to consider the use of lemmas instead of tokens:"]},{"cell_type":"code","metadata":{"id":"-2anAJyRmDuv","executionInfo":{"status":"ok","timestamp":1625823170144,"user_tz":-120,"elapsed":196,"user":{"displayName":"ISABEL SEGURA BEDMAR","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiQ1FNrqSnUE2MEN5-mH-AjUf5Ch9orkmSxxfel=s64","userId":"10362143810849156637"}}},"source":["def get_jaccard_sim3(text1, text2):\n","    \"\"\"calculates the jaccard similarity of the two input texts.\n","    We obtain lemmas instead tokens\"\"\" \n","\n","    doc1=nlp(text1)\n","    doc2=nlp(text2)\n","    lemmas1=[token.lemma_.lower() for token in doc1]\n","    lemmas2=[token.lemma_.lower() for token in doc2]\n","    \n","    set1 = set(lemmas1)\n","    set2 = set(lemmas2)\n","\n","    set_union = set1.union(set2)\n","    set_intersection = set1.intersection(set2)\n","    \n","    return len(set_intersection) / len(set_union)\n","    "],"execution_count":71,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BaYiy_R1mOos","executionInfo":{"status":"ok","timestamp":1625823552219,"user_tz":-120,"elapsed":347,"user":{"displayName":"ISABEL SEGURA BEDMAR","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiQ1FNrqSnUE2MEN5-mH-AjUf5Ch9orkmSxxfel=s64","userId":"10362143810849156637"}},"outputId":"df27e400-22f6-41c6-c11b-16b4aca85370"},"source":["s1=\"AI is our friend and it has been friendly\"\n","s2=\"AI and humans have always been friendly\"\n","\n","print(\"\\njaccard similarity (without any preprocessing) of '{}' and '{}' is : {}\".format(s1,s2,get_jaccard_sim(s1,s2)))\n","print(\"jaccard similarity (with lowercase) of '{}' and '{}' is : {}\".format(s1,s2,get_jaccard_sim2(s1,s2)))\n","print(\"jaccard similarity (with lemmas) of '{}' and '{}' is : {}\".format(s1,s2,get_jaccard_sim3(s1,s2)))"],"execution_count":77,"outputs":[{"output_type":"stream","text":["\n","jaccard similarity (without any preprocessing) of 'AI is our friend and it has been friendly' and 'AI and humans have always been friendly' is : 0.3333333333333333\n","jaccard similarity (with lowercase) of 'AI is our friend and it has been friendly' and 'AI and humans have always been friendly' is : 0.3333333333333333\n","jaccard similarity (with lemmas) of 'AI is our friend and it has been friendly' and 'AI and humans have always been friendly' is : 0.5555555555555556\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ZwBbz0BohI_-"},"source":["##Â Limitations of Jaccard similarity\n","\n","Now we can see an example of two sentences with completely opposite meanings, but with the maximum jaccard score, that is, 1. Therefore, Jaccard similarity does not consider the **order of words**, which many times is critial for the meaning of a text. "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZS0hrj1rhNnr","executionInfo":{"status":"ok","timestamp":1625823562674,"user_tz":-120,"elapsed":215,"user":{"displayName":"ISABEL SEGURA BEDMAR","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiQ1FNrqSnUE2MEN5-mH-AjUf5Ch9orkmSxxfel=s64","userId":"10362143810849156637"}},"outputId":"96a24d59-64a9-46e2-b11b-ccb00bbe4275"},"source":["s1=\"The hotel was very good, and not expensive\"\n","s2=\"The hotel was not very good, and not expensive\"\n","print(\"\\njaccard similarity of '{}' and '{}' is : {}\".format(s1,s2,get_jaccard_sim3(s1,s2)))\n"],"execution_count":78,"outputs":[{"output_type":"stream","text":["\n","jaccard similarity of 'The hotel was very good, and not expensive' and 'The hotel was not very good, and not expensive' is : 1.0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"4uUNOFnahbwE"},"source":["On the other hand, the following cell shows two sentences with very close meanings but with a very low jaccard similarity. In this case, Jaccard similarity does not take into account the **semantic relations** between words (in this case, synonymy)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L59Wwq9ThIbB","executionInfo":{"status":"ok","timestamp":1625823568211,"user_tz":-120,"elapsed":2,"user":{"displayName":"ISABEL SEGURA BEDMAR","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiQ1FNrqSnUE2MEN5-mH-AjUf5Ch9orkmSxxfel=s64","userId":"10362143810849156637"}},"outputId":"e789d036-cc70-4af0-c73d-a8224dde4a76"},"source":["s1=\"The hotel was very good, and not expensive\"\n","s2=\"The inn was especially nice, and not overprice\"\n","print(\"\\njaccard similarity of '{}' and '{}' is : {}\".format(s1,s2,get_jaccard_sim3(s1,s2)))"],"execution_count":80,"outputs":[{"output_type":"stream","text":["\n","jaccard similarity of 'The hotel was very good, and not expensive' and 'The inn was especially nice, and not overprice' is : 0.38461538461538464\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"7XifEXqeo2iy"},"source":["## More metrics to measure the lexical similarity\n","\n","Rouge is a set of metrics that can be used to measure the lexical similarity of two texts. They usually ared used for tasks such as text summarization or machine translation. For example, in text summarization, Rouge is used to compare the generated summary and the reference summary provided in the dataset. \n","\n","The most popular Rouge metrics are: \n","\n","- ROUGE-N: measures the  overlap of n-grams (sequence of n tokens) between the two texts to be compared. So, ROUGE-1 refers to the overlap of unigram, while Rouge-2 refers to the overlap of bigrams.\n","- ROUGE-L: measures the number of longest common subsequence in both texts. \n","\n","There are several python libraries that implement these metrics. For example, https://pypi.org/project/rouge/\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PA5wGSpNqOSU","executionInfo":{"status":"ok","timestamp":1625823979088,"user_tz":-120,"elapsed":3271,"user":{"displayName":"ISABEL SEGURA BEDMAR","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiQ1FNrqSnUE2MEN5-mH-AjUf5Ch9orkmSxxfel=s64","userId":"10362143810849156637"}},"outputId":"2f56fc9e-bd93-448b-98f7-68d1053a49c0"},"source":["!pip install rouge"],"execution_count":81,"outputs":[{"output_type":"stream","text":["Collecting rouge\n","  Downloading https://files.pythonhosted.org/packages/43/cc/e18e33be20971ff73a056ebdb023476b5a545e744e3fc22acd8c758f1e0d/rouge-1.0.0-py3-none-any.whl\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from rouge) (1.15.0)\n","Installing collected packages: rouge\n","Successfully installed rouge-1.0.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cwB3HJYLqbN2","executionInfo":{"status":"ok","timestamp":1625824348545,"user_tz":-120,"elapsed":199,"user":{"displayName":"ISABEL SEGURA BEDMAR","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiQ1FNrqSnUE2MEN5-mH-AjUf5Ch9orkmSxxfel=s64","userId":"10362143810849156637"}},"outputId":"4840da21-8867-4f30-91ca-fd890c4ca545"},"source":["from rouge import Rouge \n","s1=\"Where can I find the user guide\"\n","s2=\"Where can I find the manual\"\n","\n","rouge = Rouge()\n","scores = rouge.get_scores(s1, s2)\n","scores=scores[0]\n","for s in scores.keys():\n","    print(s,scores[s])"],"execution_count":100,"outputs":[{"output_type":"stream","text":["rouge-1 {'f': 0.7692307642603551, 'p': 0.7142857142857143, 'r': 0.8333333333333334}\n","rouge-2 {'f': 0.7272727223140496, 'p': 0.6666666666666666, 'r': 0.8}\n","rouge-l {'f': 0.7692307642603551, 'p': 0.7142857142857143, 'r': 0.8333333333333334}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R93PJSqvrtkH","executionInfo":{"status":"ok","timestamp":1625824358946,"user_tz":-120,"elapsed":193,"user":{"displayName":"ISABEL SEGURA BEDMAR","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiQ1FNrqSnUE2MEN5-mH-AjUf5Ch9orkmSxxfel=s64","userId":"10362143810849156637"}},"outputId":"dc02ae5a-20b8-4dd0-bd8c-24512ad9e9c8"},"source":["+s1=\"Where can I find the user guide\"\n","s2=\"Where can I find the true love\"\n","\n","rouge = Rouge()\n","scores = rouge.get_scores(s1, s2)\n","scores=scores[0]\n","for s in scores.keys():\n","    print(s,scores[s])"],"execution_count":101,"outputs":[{"output_type":"stream","text":["rouge-1 {'f': 0.7142857092857143, 'p': 0.7142857142857143, 'r': 0.7142857142857143}\n","rouge-2 {'f': 0.6666666616666668, 'p': 0.6666666666666666, 'r': 0.6666666666666666}\n","rouge-l {'f': 0.7142857092857143, 'p': 0.7142857142857143, 'r': 0.7142857142857143}\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"MjBZ-x_ar4jk"},"source":["Rouge and Jaccard share the same limitations: \n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xMPmha09rRsC","executionInfo":{"status":"ok","timestamp":1625824375335,"user_tz":-120,"elapsed":216,"user":{"displayName":"ISABEL SEGURA BEDMAR","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiQ1FNrqSnUE2MEN5-mH-AjUf5Ch9orkmSxxfel=s64","userId":"10362143810849156637"}},"outputId":"539ba4f0-41ee-46b9-dac6-16a2aa4d2d56"},"source":["s1=\"The hotel was very good, and not expensive\"\n","s2=\"The hotel was not very good, and not expensive\"\n","rouge = Rouge()\n","scores = rouge.get_scores(s1, s2)\n","scores=scores[0]\n","for s in scores.keys():\n","    print(s,scores[s])"],"execution_count":103,"outputs":[{"output_type":"stream","text":["rouge-1 {'f': 0.9411764656055364, 'p': 1.0, 'r': 0.8888888888888888}\n","rouge-2 {'f': 0.7999999950222222, 'p': 0.8571428571428571, 'r': 0.75}\n","rouge-l {'f': 0.999999995, 'p': 1.0, 'r': 1.0}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WPDIs3fgrcc3","executionInfo":{"status":"ok","timestamp":1625824373119,"user_tz":-120,"elapsed":198,"user":{"displayName":"ISABEL SEGURA BEDMAR","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiQ1FNrqSnUE2MEN5-mH-AjUf5Ch9orkmSxxfel=s64","userId":"10362143810849156637"}},"outputId":"15fb33ad-4c20-4ea7-eda3-026a2b2135c2"},"source":["from rouge import Rouge \n","\n","s1=\"The hotel was very good, and not expensive\"\n","s2=\"The inn was especially nice, and not overprice\"\n","rouge = Rouge()\n","scores = rouge.get_scores(s1, s2)\n","scores=scores[0]\n","for s in scores.keys():\n","    print(s,scores[s])"],"execution_count":102,"outputs":[{"output_type":"stream","text":["rouge-1 {'f': 0.4999999950000001, 'p': 0.5, 'r': 0.5}\n","rouge-2 {'f': 0.14285713785714302, 'p': 0.14285714285714285, 'r': 0.14285714285714285}\n","rouge-l {'f': 0.4999999950000001, 'p': 0.5, 'r': 0.5}\n"],"name":"stdout"}]}]}